{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"https://github.com/somosnlp/nlp-de-cero-a-cien/blob/main/1_word_embeddings/word2vec.ipynb","timestamp":1695488593832}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"XvNCXd9Dfqe1"},"source":["# Word2vec con Gensim\n","\n","En este cuaderno de Jupyter vas a utilizar la biblioteca [Gensim](https://radimrehurek.com/gensim/index.html) para experimentar con word2vec. Este cuaderno está enfocado en la intuición de los conceptos y no en los detalles de implementación. Este cuaderno está inspirado en esta [guía](https://radimrehurek.com/gensim/auto_examples/tutorials/run_word2vec.html).\n","\n","Para ver qué se puede hacer con Word2Vec, descarguemos un modelo previamente entrenado y jugaremos con él. Obtendremos el modelo Word2Vec entrenado con un conjunto de datos de Google News, que abarca aproximadamente 3 millones de palabras y frases. Un modelo de este tipo puede tardar horas en entrenarse, pero como ya está disponible, descargarlo y cargarlo con Gensim lleva unos minutos.\n","\n","**Importante**\n","\n","El modelo tiene aproximadamente 2 GB, por lo que necesitarás una conexión de red decente para continuar.\n","\n","\n","## 1. Instalación y cargar el modelo"]},{"cell_type":"code","metadata":{"id":"zKIqnDXXfpiz"},"source":["!pip install --upgrade gensim"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Sn7Q2jB3frOn"},"source":["import gensim.downloader as api"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yBaT8djWkaZy"},"source":["#bajar modelo\n","model = api.load('word2vec-google-news-300')"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model[\"king\"].shape"],"metadata":{"id":"tA-cTRItltKh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model[\"king\"]"],"metadata":{"id":"3HeiFZzl1cyM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nVZm7iTOoawW"},"source":["## 2. Similitud de palabras\n","\n","En esta sección veremos cómo conseguir la similitud entre dos palabras utilizando un word embedding ya entrenado."]},{"cell_type":"code","metadata":{"id":"kOZfaelLoi4c"},"source":["model.similarity(\"king\", \"queen\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BX-Kk9HZofuF"},"source":["model.similarity(\"king\", \"man\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ypFK-pLrol3N"},"source":["model.similarity(\"king\", \"potato\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rBWzZySFormq"},"source":["model.similarity(\"king\", \"king\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9GijWs_tx83W"},"source":["Ahora veremos cómo encontrar las palabras con mayor similitud al conjunto de palabras especificado."]},{"cell_type":"code","metadata":{"id":"ytELAWBLk2-6"},"source":["model.most_similar([\"king\", \"queen\"], topn=5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7D4ZS7N3ovxB"},"source":["model.most_similar([\"tomato\", \"carrot\"], topn=5)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WZFlxKjOyBpu"},"source":["Pero incluso puedes hacer cosas interesantes como ver qué palabra no corresponde a una lista."]},{"cell_type":"code","metadata":{"id":"8CrZdcBpn3pn"},"source":["model.doesnt_match([\"summer\", \"fall\", \"spring\", \"air\"])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ko09hZ3dqMZ1"},"source":["## Ejercicios\n","\n","1. Usa el modelo word2vec para hacer un ranking de las siguientes 15 palabras según su similitud con las palabras \"man\" y \"woman\". Para cada par, imprime su similitud."]},{"cell_type":"code","metadata":{"id":"vzZ1eD3PpT-d"},"source":["words = [\n","\"wife\",\n","\"husband\",\n","\"child\",\n","\"queen\",\n","\"king\",\n","\"man\",\n","\"woman\",\n","\"birth\",\n","\"doctor\",\n","\"nurse\",\n","\"teacher\",\n","\"professor\",\n","\"engineer\",\n","\"scientist\",\n","\"president\"]\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EKamywnxqxJJ"},"source":["**2. Completa las siguientes analogías por tu cuenta (sin usar el modelo)**\n","\n","a. king is to throne as judge is to _\n","\n","b. Usa is to burger as Mexico is _\n","\n","c. French is to France as Spaniard is to _\n","\n","d. bad is to good as sad is to _\n","\n","e. nurse is to hospital as teacher is to _\n","\n","f. universe is to planet as house is to _"]},{"cell_type":"markdown","metadata":{"id":"VcNRxHuZrXAM"},"source":["**2. Ahora completa las analogías usando un modelo word2vec**\n","\n","Aquí hay un ejemplo de cómo hacerlo. Puedes resolver analogías como \"A es a B como C es a _\" haciendo  C + B - A."]},{"cell_type":"code","metadata":{"id":"K4kF08h4qhxM"},"source":["# man is to woman as king is to ___?\n","model.most_similar(positive=[\"king\", \"woman\"], negative=[\"man\"], topn=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DiPbbGsori48"},"source":["# usa is to burger as Mexico is to ___?\n","model.most_similar(positive=[\"Mexico\", \"burger\"], negative=[\"USA\"], topn=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# nurse is to hospital as teacher is to ___?\n","model.most_similar(positive=[\"teacher\", \"hospital\"], negative=[\"nurse\"], topn=1)"],"metadata":{"id":"YFF4Gk9AZxwh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# king is to throne as judge is to ___?\n","model.most_similar(positive=[\"judge\", \"throne\"], negative=[\"king\"], topn=1)"],"metadata":{"id":"0pRWB7yPaXLh"},"execution_count":null,"outputs":[]}]}